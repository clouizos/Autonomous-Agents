\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Environment: Should we keep this?}{2}}
\newlabel{environment}{{1.1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods and Procedures}{3}}
\newlabel{methods}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\textbf  {Action selection}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\textbf  {On-Policy Monte Carlo}}{3}}
\newlabel{returnOn}{{2.2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces On-policy Monte Carlo Control Pseudo-code}}{4}}
\newlabel{onmc}{{2.1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\textbf  {Off-Policy Monte Carlo}}{4}}
\newlabel{eq:relative prob 1}{{2.4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Off-Policy Monte Carlo Control Pseudo-code}}{6}}
\newlabel{figure:offPolicy}{{2.2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}\textbf  {Sarsa}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Sarsa Pseudo-code}}{7}}
\newlabel{figure:Sarsa}{{2.3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}\textbf  {Q-learning}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Q-learning: An off-policy TD control algorithm.}}{8}}
\newlabel{figure:Q}{{2.4}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Reducing the state space}{8}}
\newlabel{reduce}{{2.6}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Runtime of normal and reduced statespace in seconds}}{9}}
\newlabel{runtime}{{2.1}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Values from value iteration when the prey is at [3][2]}}{9}}
\newlabel{rVIt}{{2.2}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiments and Results}{9}}
\newlabel{results}{{3}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Theoretical Differences}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}On-Policy Monte Carlo Control}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Off-Policy Monte Carlo Control}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Catching time with different fixed epsilon value}}{10}}
\newlabel{figure:differentFixEpsilon}{{3.1}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Catch time with fix epsilon value}}{11}}
\newlabel{figure:fixEpsilon}{{3.2}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Catching time with dynamic epsilon value}}{12}}
\newlabel{figure:dynamicEpsilon}{{3.3}{12}}
\newlabel{figure:dynamicEpsilon}{{3.3}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Catch time with dynamic epsilon value}}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Target Policy Off-Policy Monte Carlo Control}}{13}}
\newlabel{table:TargetPolicy}{{3.1}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Policy evaluation results}}{14}}
\newlabel{PE parameter}{{3.2}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces State values for the following states}}{14}}
\newlabel{PE states values}{{3.3}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Policy Iteration}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Convergence in iterations for different $\gamma $}}{14}}
\newlabel{convPIter}{{3.4}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Values from policy iteration when the prey is at [5][5]}}{15}}
\newlabel{pitS}{{3.5}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Value Iteration}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Convergence in iterations for different $\gamma $}}{15}}
\newlabel{convVIter}{{3.6}{15}}
\bibcite{suttonBarto}{1}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces Values from value iteration when the prey is at [5][5]}}{16}}
\newlabel{vitS}{{3.7}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Comparison of Policy and Value iteration}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Comparative graph of convergence for policy and value iteration}}{16}}
\newlabel{converge}{{3.5}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {4}conclusion}{16}}
\newlabel{discussion}{{4}{16}}
