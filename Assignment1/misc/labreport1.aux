\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Environment}{3}}
\newlabel{environment}{{1.1}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods and Procedures}{4}}
\newlabel{methods}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Implementation overview}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Predator-prey domain framework}}{4}}
\newlabel{Predator-prey domain framework}{{2.1}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Random policies implemented}}{4}}
\newlabel{Policies1}{{2.2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Policy evaluation and iteration implemented}}{5}}
\newlabel{Policies2}{{2.3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Policy value iteration implemented}}{5}}
\newlabel{Policies3}{{2.4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Iterative Policy Evaluation}{6}}
\newlabel{oriV}{{2.1}{6}}
\newlabel{iterV}{{2.2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Iterative Policy Evaluation}}{6}}
\newlabel{Iterative Policy Evaluation Pseudo}{{2.5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Policy Iteration}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Policy Iteration}}{7}}
\newlabel{Policy Iteration}{{2.6}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Value Iteration}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Value Iteration}}{8}}
\newlabel{Value Iteration}{{2.7}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Reducing the state space}{8}}
\newlabel{reduce}{{2.5}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{8}}
\newlabel{results}{{3}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Random Policy}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Random policy results}}{8}}
\bibcite{suttonBarto}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Iterative Policy Evaluation}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Policy evaluation results}}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces State values for the following states}}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Policy Iteration}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Convergence in iterations for different $\gamma $}}{9}}
\newlabel{convPIter}{{3.4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Value Iteration}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Values from policy iteration when the prey is at [5][5]}}{10}}
\newlabel{pitS}{{3.5}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Convergence in iterations for different $\gamma $}}{10}}
\newlabel{convVIter}{{3.6}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{10}}
\newlabel{discussion}{{4}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces Values from value iteration when the prey is at [5][5]}}{11}}
\newlabel{pitS}{{3.7}{11}}
